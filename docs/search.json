[
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "ESS 330: Lab 6",
    "section": "",
    "text": "#Attaching packages\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.1     \n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\n\nWarning: package 'glue' was built under R version 4.4.3\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\n\n#Downloading PDF and data\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\n#Question 1\n\n#zero_q_freq represents the frequency of days with Q=0 mm/day, reported as a percentage\n\n##Exploratory data analysis\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()\n\n\n\n\n\n\n\n\n#Question 2\n\n#Map 1 for aridity \nmap_aridity &lt;- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = aridity)) +\n  scale_color_gradient(low = \"cornsilk\", high = \"red4\") +\n  ggthemes::theme_map() + labs(title = \"Aridity\")\n\n#Map 2 for p_mean\nmap_p_mean &lt;- ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = p_mean)) +\n  scale_color_gradient(low = \"lightblue2\", high = \"darkblue\") +\n  ggthemes::theme_map() + labs(title = \"Mean Daily Precipitation\")\n\nlibrary(patchwork)\nmap_aridity + map_p_mean\n\n\n\n\n\n\n\n\n#Model Preparation\n\ncamels |&gt; \n  select(aridity, p_mean, q_mean) |&gt; \n  drop_na() |&gt; \n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\n#Visual EDA\n\n# Create a scatter plot of aridity vs rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  # Add points colored by mean flow\n  geom_point(aes(color = q_mean)) +\n  # Add a linear regression line\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  # Apply the viridis color scale\n  scale_color_viridis_c() +\n  # Add a title, axis labels, and theme (w/ legend on the bottom)\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  # Apply a log transformation to the color scale\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n#Model Building\n\nset.seed(123)\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\n# Generate the split\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n# Create a recipe to preprocess the data\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  # Log transform the predictor variables (aridity and p_mean)\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) |&gt; \n  step_naomit(all_predictors(), all_outcomes())\n\n# Prepare the data\nbaked_data &lt;- prep(rec, camels_train) |&gt; \n  bake(new_data = NULL)\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\n#Model Evaluation\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  # Apply a gradient color scale\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n#Using a workflow\n\n# Define model\nlm_model &lt;- linear_reg() %&gt;%\n  # define the engine\n  set_engine(\"lm\") %&gt;%\n  # define the mode\n  set_mode(\"regression\")\n\n# Instantiate a workflow ...\nlm_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(lm_model) %&gt;%\n  # Fit the model to the training data\n  fit(data = camels_train) \n\n# Extract the model coefficients from the workflow\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n# From the base implementation\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\n#Making Predictions + Model Evaluation\n\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  61\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n#Switch it Up\n\nlibrary(baguette)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.4.3\n\nrf_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(rf_model) %&gt;%\n  # Fit the model\n  fit(data = camels_train) \n\n#Predictions and Model Evaluation\n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.588\n2 rsq     standard       0.740\n3 mae     standard       0.365\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n#Workflowset approach\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.564  0.0253    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.770  0.0260    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2\n\n\n#Question 3\n\nlibrary(xgboost)\n\nWarning: package 'xgboost' was built under R version 4.4.3\n\n\n\nAttaching package: 'xgboost'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\n#Build a xgboost (engine) regression (mode) model using boost_tree\nset.seed(123) \ndata_split &lt;- initial_split(camels, prop = 0.8)\ntrain_data &lt;- training(data_split)\ntest_data &lt;- testing(data_split)\n\nxgb_model &lt;- boost_tree(\n  mode = \"regression\",  \n  trees = 1000,         \n  tree_depth = 6,         \n  learn_rate = 0.1,       \n  mtry = 5,               \n  min_n = 10) %&gt;%\n  set_engine(\"xgboost\")   \n\n#Build neural network model using the nnet engine from the baguette package using the bag_mlp function\nnn_model &lt;- bag_mlp(\n  mode = \"regression\",   \n  hidden_units = 10,     \n  epochs = 100,          \n  penalty = 0.01) %&gt;%\n  set_engine(\"nnet\")  \n\n#Add workflows for each model\nworkflow_xgb &lt;- workflow() %&gt;%\n  add_model(xgb_model) %&gt;%\n  add_recipe(rec)\n\nworkflow_nn &lt;- workflow() %&gt;%\n  add_model(nn_model) %&gt;%\n  add_recipe(rec)\n\n#Train models\nxgb_fit &lt;- fit(workflow_xgb, data = train_data)\nnn_fit &lt;- fit(workflow_nn, data = train_data)\nlm_fit &lt;- fit(lm_wf, data = train_data)\nrf_fit &lt;- fit(rf_wf, data = train_data)\n\n#Predictions for models\nxgb_preds &lt;- predict(xgb_fit, new_data = test_data)\nnn_preds &lt;- predict(nn_fit, new_data = test_data)\nlm_preds &lt;- predict(lm_fit, new_data = test_data)\nrf_preds &lt;- predict(rf_fit, new_data = test_data)\n\n#Combine predictions and true values\nxgb_results &lt;- bind_cols(test_data, xgb_preds)\nnn_results &lt;- bind_cols(test_data, nn_preds)\nlm_results &lt;- bind_cols(test_data, lm_preds)\nrf_results &lt;- bind_cols(test_data, rf_preds)\n\n\n#Evaluate using R-squared\nxgb_rsq &lt;- rsq(xgb_results, truth = q_mean, estimate = .pred)\nnn_rsq &lt;- rsq(nn_results, truth = q_mean, estimate = .pred)\nlm_rsq &lt;- rsq(lm_results, truth = q_mean, estimate = .pred)\nrf_rsq &lt;- rsq(rf_results, truth = q_mean, estimate = .pred)\n\n#Print results to compare\nprint(paste(\"XGBoost Model Performance:\"))\n\n[1] \"XGBoost Model Performance:\"\n\nprint(paste(\"  R-squared: \", round(xgb_rsq$.estimate, 3)))\n\n[1] \"  R-squared:  0.453\"\n\nprint(paste(\"\\nNeural Network Model Performance:\"))\n\n[1] \"\\nNeural Network Model Performance:\"\n\nprint(paste(\"  R-squared: \", round(nn_rsq$.estimate, 3)))\n\n[1] \"  R-squared:  0.551\"\n\nprint(paste(\"\\nLinear Regression Model Performance:\"))\n\n[1] \"\\nLinear Regression Model Performance:\"\n\nprint(paste(\"  R-squared: \", round(lm_rsq$.estimate, 3)))\n\n[1] \"  R-squared:  0.599\"\n\nprint(paste(\"\\nRandom Forest Model Performance:\"))\n\n[1] \"\\nRandom Forest Model Performance:\"\n\nprint(paste(\"  R-squared: \", round(rf_rsq$.estimate, 3)))\n\n[1] \"  R-squared:  0.532\"\n\n#ANSWER: Based on the results of each model and the corresponding R-squared values, neural network is the best model to move forward with. This is because neural network has the 2nd highest R-squared value at 0.551, following linear regression. While linear regression has the highest value at 0.599, as shown previously, the data has a non-linear relationship meaning that neural network is a better model overall.\n\n#Build Your Own ##Data spliting\n\nlibrary(workflows)\nlibrary(tune)\nlibrary(rsample)\nlibrary(yardstick)\n\n#remove NA values\nlibrary(dplyr)\ncamels_train_clean &lt;- camels_train %&gt;%\n  filter(!is.na(logQmean))\nsum(is.na(camels_train_clean$logQmean))\n\n[1] 0\n\nset.seed(123)\n# Bad form to perform simple transformations on the outcome variable within a \n# recipe. So, we'll do it here.\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\n\n# Generate the split\ncamels_split &lt;- initial_split(camels_train_clean, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\n#Cross validation\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n##Recipe\n\n#Formula\nlogQmean ~ p_mean + elev_mean + slope_mean + aridity + runoff_ratio\n\nlogQmean ~ p_mean + elev_mean + slope_mean + aridity + runoff_ratio\n\n#Why this formula?\n#I am choosing this formula because each of these factors can have a significant impact on stream flow. For example, rainfall is the primary input of new stream flow within a watershed and aridity mean that stream flow is less likely. Both elevation and slope can contribute to how much runoff there is in an area, ultimately impacting stream flow. \n\n#Recipe\nrec &lt;- recipe(logQmean ~ p_mean + elev_mean + slope_mean + aridity + runoff_ratio, \n              data = camels_train) %&gt;%\nstep_normalize(all_numeric(), -all_outcomes()) %&gt;%\nstep_impute_median(all_numeric(), -all_outcomes()) \n\n##Define 3 Models\n\nrf_model &lt;- rand_forest(mode = \"regression\", trees = 500, mtry = 3, min_n = 10) %&gt;%\n  set_engine(\"ranger\")\n\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")\n\nxgb_model &lt;- boost_tree(mode = \"regression\", trees = 1000, tree_depth = 6, learn_rate = 0.1, min_n = 10) %&gt;%\n  set_engine(\"xgboost\")\n\n##Create Workflows\n\n#Define the workflows for each model\nworkflow_rf &lt;- workflow() %&gt;%\n  add_model(rf_model) %&gt;%\n  add_recipe(rec)   \n\nworkflow_lm &lt;- workflow() %&gt;%\n  add_model(lm_model) %&gt;%\n  add_recipe(rec)  \n\nworkflow_xgb &lt;- workflow() %&gt;%\n  add_model(xgb_model) %&gt;%\n  add_recipe(rec)   \n\nmodels &lt;- list(\n  \"Random Forest\" = rf_model, \n  \"Linear Regression\" = lm_model, \n  \"XGBoost\" = xgb_model)\n\nrecipes &lt;- list(\n  \"Standard\" = rec)\n\nworkflow_set &lt;- workflow_set(preproc = recipes, \n  models = models)\n\nset.seed(123)  \n\nresults &lt;- workflow_set %&gt;%\n  workflow_map(resamples = camels_cv,\n    seed = 123,             \n    metrics = metric_set(rmse, rsq))\n\n#Evaluation\n\nautoplot(results, metric = \"rmse\") \n\n\n\n\n\n\n\nautoplot(results, metric = \"rsq\")\n\n\n\n\n\n\n\nranked_results &lt;- rank_results(results)\nprint(ranked_results)\n\n# A tibble: 6 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 Standard_Random … Prepro… rmse    0.127 0.0204     10 recipe       rand…     1\n2 Standard_Random … Prepro… rsq     0.989 0.00356    10 recipe       rand…     1\n3 Standard_XGBoost  Prepro… rmse    0.162 0.0251     10 recipe       boos…     2\n4 Standard_XGBoost  Prepro… rsq     0.984 0.00405    10 recipe       boos…     2\n5 Standard_Linear … Prepro… rmse    0.420 0.0260     10 recipe       line…     3\n6 Standard_Linear … Prepro… rsq     0.883 0.00765    10 recipe       line…     3\n\n#ANSWER: Based on the results, the rand_forest model is the best because it has the highest r-squared value at 0.988\n\n##Extract and Evaluate\n\nlibrary(ggplot2)\n\n#Build model\nrf_model &lt;- rand_forest(\n  mode = \"regression\",  \n  trees = 500,          \n  mtry = 3,             \n  min_n = 10) %&gt;%\n  set_engine(\"ranger\")\n\n#Define recipe\nrec &lt;- recipe(logQmean ~ p_mean + elev_mean + slope_mean + aridity + runoff_ratio, \n              data = camels_train) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes()) %&gt;%\n  step_impute_median(all_numeric(), -all_outcomes())\n\n#Build Workflow\nworkflow_rf &lt;- workflow() %&gt;%\n  add_model(rf_model) %&gt;%\n  add_recipe(rec)\n\n#Fit model to training data\nrf_fit &lt;- fit(workflow_rf, data = camels_train)\n\n#Make prediction on test data using augment\nrf_predictions &lt;- augment(rf_fit, new_data = camels_test)\n\n#Plot observed vs predicted\nggplot(rf_predictions, aes(x = logQmean, y = .pred)) +\n  geom_point(color = \"blue\", alpha = 0.6) +  # Blue points for observed vs predicted\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +  # Identity line\n  labs(\n    title = \"Observed vs Predicted Streamflow (logQmean)\",\n    x = \"Observed Streamflow (logQmean)\",\n    y = \"Predicted Streamflow (logQmean)\"\n  ) +\n  theme_minimal() +\n  scale_color_viridis_c()\n\n\n\n\n\n\n\n#Description of results\n#Based on the scatter plot, the data is remaining fairly close to the dashed line, showing that the model's predictions closely align with the actual observed values. While the points are pretty well distributed, there are the most points from 0.8 to 1. The strong indicator of 0.988 suggests that this is a strong model and that the Random Forest model is performing well. The model explains a significant amount of the variability in the observed stream flow."
  },
  {
    "objectID": "hyperparameter-tuning.html",
    "href": "hyperparameter-tuning.html",
    "title": "hyperparameter-tuning",
    "section": "",
    "text": "Load in packages\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.1     \n\n\nWarning: package 'recipes' was built under R version 4.4.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(powerjoin)\n\nWarning: package 'powerjoin' was built under R version 4.4.3\n\nlibrary(glue)\n\nWarning: package 'glue' was built under R version 4.4.3\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.4.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.4.3\n\nlibrary(dplyr)\nlibrary(visdat)\n\nWarning: package 'visdat' was built under R version 4.4.3\n\nlibrary(ggpubr)\n\nWarning: package 'ggpubr' was built under R version 4.4.3\n\nlibrary(rsample)\nlibrary(recipes)\nlibrary(parsnip)\nlibrary(workflows)\nlibrary(tune)\nlibrary(yardstick)\nlibrary(ggplot2)\n\n\n\nRead in data\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\n\n\nClean data\n\nvis_dat(camels)\n\n\n\n\n\n\n\ncamels_clean &lt;- camels %&gt;%\n  drop_na()\nvis_dat(camels_clean)\n\n\n\n\n\n\n\ncamels_clean &lt;- camels_clean %&gt;%\n  mutate(logQmean = log(q_mean))\n\n\n\nData splitting\n\nset.seed(123)\nsplit_data &lt;- initial_split(camels_clean, prop = 0.8)\ncamels_train &lt;- training(split_data)\ncamels_test  &lt;- testing(split_data)\n\n\n\nFeature engineering\n\nrec &lt;- recipe(q_mean ~ p_mean + slope_mean + aridity, \n              data = camels_train) %&gt;%\n  step_log(q_mean, base = exp(1)) %&gt;% \n  step_impute_median(all_numeric(), -all_outcomes()) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes())\n\n\n\nResampling + Model Testing\n\n# Build resamples\ncv_splits &lt;- vfold_cv(camels_train, v = 10)\n\n# Build 3 Candidate Models \n# Linear regression \nlin_spec &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n# Random Forest \nrf_spec &lt;- rand_forest(trees = 500) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n# Neural Network\nnn_spec &lt;- mlp(hidden_units = 5, penalty = 0.01, epochs = 100) %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\n# Workflows \nlin_wf &lt;- workflow() %&gt;%\n  add_model(lin_spec) %&gt;%\n  add_recipe(rec)\n\nrf_wf &lt;- workflow() %&gt;%\n  add_model(rf_spec) %&gt;%\n  add_recipe(rec)\n\nnn_wf &lt;- workflow() %&gt;%\n  add_model(nn_spec) %&gt;%\n  add_recipe(rec)\n\n# Test the model\nmodel_set &lt;- workflow_set(\n  preproc = list(rec), \n  models = list(lin_mod = lin_spec, rf_mod = rf_spec, nn_mod = nn_spec))\n\ncv_results &lt;- workflow_map(\n  object = model_set,\n  resamples = cv_splits,\n  metrics = metric_set(rmse, rsq),  \n  verbose = TRUE)\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 1 of 3 resampling: recipe_lin_mod\n\n\n✔ 1 of 3 resampling: recipe_lin_mod (860ms)\n\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 2 of 3 resampling: recipe_rf_mod\n\n\nWarning: package 'ranger' was built under R version 4.4.3\n\n\n✔ 2 of 3 resampling: recipe_rf_mod (1.7s)\n\n\ni   No tuning parameters. `fit_resamples()` will be attempted\n\n\ni 3 of 3 resampling: recipe_nn_mod\n\n\n✔ 3 of 3 resampling: recipe_nn_mod (1s)\n\nautoplot(cv_results)\n\n\n\n\n\n\n\n\n\n\nModel Selection\n\n\nBased on the results above, the neural network model is performing the best. This model has the lowest RMSE and the highest RSQ. This means that the model is making the most accurate predictions and that more of the variance is being explained by the model.\n\n\nThe neural network is a deep learning model, composed of layers of interconnected nodes that are designed to caputre complex patterns and relationships within the data. The engine being used is nnet which allows us to train neural networks with one ore more hidden layers. The mode is regression mode since we are predicting a continuous outcome. Neural network is performing well because it is great at modeling complex non-linear relationships as we may often see in hydrological data. It is also good at handling large data sets with lots of predictors.\n\n\nModel Tuning\n\n#1: Build a model \nnn_spec &lt;- mlp(hidden_units = tune(), penalty = tune()) %&gt;%  \n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n#2: Create a workflow\nnn_wf &lt;- workflow() %&gt;%\n  add_model(nn_spec) %&gt;%\n  add_recipe(rec)\n\n#3: Extract the parameter set dials for your model workflow\ndials &lt;- extract_parameter_set_dials(nn_wf)\n\n# Check the object slot to see the tunable parameters and their ranges\ndials$object\n\n[[1]]\n# Hidden Units (quantitative)\nRange: [1, 10]\n\n[[2]]\nAmount of Regularization (quantitative)\nTransformer: log-10 [1e-100, Inf]\nRange (transformed scale): [-10, 0]\n\n#4: Create a grid using Latin Hypercube sampling with size = 25\nmy.grid &lt;- grid_space_filling(dials$object, size = 25)\nhead(my.grid)\n\n# A tibble: 6 × 2\n  hidden_units  penalty\n         &lt;int&gt;    &lt;dbl&gt;\n1            1 6.81e- 5\n2            1 8.25e- 8\n3            1 2.15e- 2\n4            2 6.81e-10\n5            2 3.83e- 6\n6            2 4.64e- 4\n\n#5: Tune the model\ncv_results_nn &lt;- tune_grid(\n  nn_wf,\n  resamples = cv_splits, \n  grid = my.grid, \n  metrics = metric_set(rmse, rsq, mae),\n  control = control_grid(save_pred = TRUE))\nautoplot(cv_results_nn)\n\n\n\n\n\n\n\n#6: Check the skill of the tuned model\nmetrics_df &lt;- collect_metrics(cv_results_nn)\nmetrics_df %&gt;%\n  filter(.metric == \"mae\") %&gt;%        \n  arrange(mean)   \n\n# A tibble: 25 × 8\n   hidden_units       penalty .metric .estimator  mean     n std_err .config    \n          &lt;int&gt;         &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n 1            9 0.0000261     mae     standard   0.236    10 0.00977 Preprocess…\n 2            6 0.0000000001  mae     standard   0.237    10 0.0109  Preprocess…\n 3           10 0.00825       mae     standard   0.237    10 0.00913 Preprocess…\n 4            6 0.0562        mae     standard   0.239    10 0.00903 Preprocess…\n 5            9 0.00000000178 mae     standard   0.239    10 0.00975 Preprocess…\n 6            7 0.0000000121  mae     standard   0.240    10 0.00964 Preprocess…\n 7           10 0.000000215   mae     standard   0.242    10 0.0119  Preprocess…\n 8            5 0.00000000464 mae     standard   0.244    10 0.00830 Preprocess…\n 9            8 0.00121       mae     standard   0.244    10 0.0107  Preprocess…\n10            7 0.00000147    mae     standard   0.245    10 0.00920 Preprocess…\n# ℹ 15 more rows\n\nshow_best(cv_results_nn, metric = \"mae\", n = 1)\n\n# A tibble: 1 × 8\n  hidden_units   penalty .metric .estimator  mean     n std_err .config         \n         &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           \n1            9 0.0000261 mae     standard   0.236    10 0.00977 Preprocessor1_M…\n\nautoplot(cv_results_nn)\n\n\n\n\n\n\n\n# Based on the results above, the best model is number of hidden units and regularization penalty. This is because the MAE of 0.8 indicates that the neural network has a relatively low prediction error. The hyperparameter combination of hidden_units = 100 and penalty = 0.01 produces this low error. \n\n#Use the select_best() function to save the best performing hyperparameter set to an object called hp_best\nhp_best &lt;- select_best(cv_results_nn, metric = \"mae\")\nhp_best\n\n# A tibble: 1 × 3\n  hidden_units   penalty .config              \n         &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;                \n1            9 0.0000261 Preprocessor1_Model23\n\n# Finalize the model\nfinal_wf &lt;- finalize_workflow(nn_wf, hp_best)\nfinal_wf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: mlp()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_log()\n• step_impute_median()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nSingle Layer Neural Network Model Specification (regression)\n\nMain Arguments:\n  hidden_units = 9\n  penalty = 2.61015721568254e-05\n\nComputational engine: nnet \n\n\n#Final model verification\n\nfinal_results &lt;- last_fit(final_wf, split = split_data)\nfinal_results\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits            id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;            &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [405/102]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\nfinal_metrics &lt;- collect_metrics(final_results)\nprint(final_metrics)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.496 Preprocessor1_Model1\n2 rsq     standard       0.869 Preprocessor1_Model1\n\n# Interpretation: Based on the results, the model performs well on the test data. The RMSE value of 0.092 is very low, suggesting a low level of prediction error. The R-squared value of 0.996 is quite high, showing that the model performed well and that the model explains most of the variability in the q_mean. The final model is performing better than the training data, suggesting it good at generalization and is not overfitting. \n\nfinal_predictions &lt;- collect_predictions(final_results)\nprint(final_predictions)\n\n# A tibble: 102 × 5\n    .pred id                .row   q_mean .config             \n    &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n 1 0.841  train/test split     1  0.776   Preprocessor1_Model1\n 2 0.369  train/test split    15  0.620   Preprocessor1_Model1\n 3 1.01   train/test split    17  0.805   Preprocessor1_Model1\n 4 0.800  train/test split    19  0.766   Preprocessor1_Model1\n 5 0.628  train/test split    28  0.707   Preprocessor1_Model1\n 6 0.117  train/test split    37  0.0948  Preprocessor1_Model1\n 7 0.149  train/test split    38  0.151   Preprocessor1_Model1\n 8 0.190  train/test split    44 -0.00956 Preprocessor1_Model1\n 9 0.108  train/test split    46  0.132   Preprocessor1_Model1\n10 0.0719 train/test split    47  0.00388 Preprocessor1_Model1\n# ℹ 92 more rows\n\nfinal_predictions &lt;- final_predictions %&gt;%\n  mutate(id = row_number()) %&gt;%\n  left_join(camels_test %&gt;% mutate(id = row_number()), by = \"id\") %&gt;%\n  select(-id)\n\n# Scatter plot\n\nggplot(final_predictions, aes(x = camels_test$q_mean, y = .pred)) +\n  geom_point(aes(color = .pred), size = 3, alpha = 0.7) + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n  scale_color_viridis_c() +\n  labs(\n    title = \"Predicted vs Actual Values\",\n    x = \"Actual Values\",\n    y = \"Predicted Values\",\n    color = \"Predicted Value\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nBuilding a map!\n\n# Fit the finalized workflow to the entire cleaned data (before splitting)\nfinal_model &lt;- fit(final_wf, data = camels_clean)\n\n# Generate predictions and residuals\nfull_predictions &lt;- augment(final_model, new_data = camels_clean)\n\n# Calculate the residuals (actual - predicted)\nfull_predictions &lt;- full_predictions %&gt;%\n  mutate(residuals = .pred - q_mean,        \n         residuals_squared = residuals^2)     \n\n\n# Map of Predictions\nlibrary(ggplot2)\nmap_predictions &lt;- ggplot(full_predictions, aes(x = gauge_lon, y = gauge_lat, color = .pred)) +   borders(\"state\", colour = \"gray80\", fill = NA) +\n  geom_point(size = 2, alpha = 0.7) +\n  coord_fixed(1.3) +\n  scale_color_viridis_c() +\n  labs(\n    title = \"Predicted Streamflow Across CONUS\",\n    x = \"Longitude\",\n    y = \"Latitude\",\n    color = \"Predicted Qmean\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n# Map of residuals \nmap_residuals &lt;- ggplot(full_predictions, aes(x = gauge_lon, y = gauge_lat, color = residuals)) +   borders(\"state\", colour = \"gray80\", fill = NA) +\n  geom_point(size = 2, alpha = 0.7) +\n  coord_fixed(1.3) +\n  scale_color_viridis_c() +\n  labs(\n    title = \"Residuals of Predicted Streamflow Across CONUS\",\n    x = \"Longitude\",\n    y = \"Latitude\",\n    color = \"Residuals\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n# Combined maps\nlibrary(patchwork)\ncombined_map &lt;- map_predictions + map_residuals +\n  plot_layout(ncol = 1)  \ncombined_map"
  }
]